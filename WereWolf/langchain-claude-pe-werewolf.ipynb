{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35db18b4-3f20-4090-9402-69ec7c684739",
   "metadata": {},
   "source": [
    "# Bedrock with LangChain using a Prompt that includes Context\n",
    "\n",
    "please refer the detail : https://github.com/aws-samples/amazon-bedrock-workshop/blob/main/01_Generation/02_contextual_generation.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe8c40c-20fe-4af0-864e-8e6c828de6b4",
   "metadata": {},
   "source": [
    "## install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca77056f-30e2-4871-8d34-9574db3ea726",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (1.34.55)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.55 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3) (1.34.55)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from botocore<1.35.0,>=1.34.55->boto3) (2.8.2)\n",
      "Requirement already satisfied: urllib3<2.1,>=1.25.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from botocore<1.35.0,>=1.34.55->boto3) (2.0.7)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.55->boto3) (1.16.0)\n",
      "Requirement already satisfied: langchain in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.1.7)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (2.0.27)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (3.9.3)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (0.6.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.20 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (0.0.20)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.22 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (0.1.23)\n",
      "Requirement already satisfied: langsmith<0.1,>=0.0.83 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (0.0.87)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (1.26.1)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (2.4.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: anyio<5,>=3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain-core<0.2,>=0.1.22->langchain) (4.0.0)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain-core<0.2,>=0.1.22->langchain) (23.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.22->langchain) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.22->langchain) (1.1.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: langchainhub in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.1.14)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchainhub) (2.31.0)\n",
      "Requirement already satisfied: types-requests<3.0.0.0,>=2.31.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchainhub) (2.31.0.20240125)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3,>=2->langchainhub) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3,>=2->langchainhub) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3,>=2->langchainhub) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3,>=2->langchainhub) (2023.7.22)\n",
      "Requirement already satisfied: anthropic in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.16.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anthropic) (4.0.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anthropic) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anthropic) (0.26.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anthropic) (2.4.2)\n",
      "Requirement already satisfied: sniffio in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anthropic) (1.3.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anthropic) (0.15.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anthropic) (4.8.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio<5,>=3.5.0->anthropic) (3.4)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio<5,>=3.5.0->anthropic) (1.1.3)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from httpx<1,>=0.23.0->anthropic) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from httpx<1,>=0.23.0->anthropic) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->anthropic) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->anthropic) (2.10.1)\n",
      "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tokenizers>=0.13.0->anthropic) (0.20.3)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.12.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2023.10.0)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (4.66.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (6.0.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (23.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.3.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2.0.7)\n"
     ]
    }
   ],
   "source": [
    "# dependencies\n",
    "!pip install --upgrade boto3\n",
    "!pip install langchain\n",
    "!pip install langchainhub\n",
    "!pip install anthropic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65343449-e808-4e95-8085-db8cbf2cda73",
   "metadata": {},
   "source": [
    "## check bedrock availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8040cab-2932-4308-9ff7-4bc07ec3b904",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def usage_demo():\n",
    "    \"\"\"\n",
    "    Shows how to list the available foundation models.\n",
    "    This demonstration gets the list of available foundation models and\n",
    "    prints their respective summaries.\n",
    "    \"\"\"\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    print(\"-\" * 88)\n",
    "    print(\"Welcome to the Amazon Bedrock demo.\")\n",
    "    print(\"-\" * 88)\n",
    "\n",
    "    bedrock_client = boto3.client(service_name=\"bedrock\", region_name=\"us-east-1\")\n",
    "\n",
    "    wrapper = BedrockWrapper(bedrock_client)\n",
    "\n",
    "    print(\"Listing the available foundation models.\")\n",
    "\n",
    "    try:\n",
    "        for model in wrapper.list_foundation_models():\n",
    "            print_model_details(model)\n",
    "    except ClientError:\n",
    "        logger.exception(\"Couldn't list foundation models.\")\n",
    "        raise\n",
    "\n",
    "    print(\"Getting the details of an individual foundation model.\")\n",
    "\n",
    "    model_id = \"amazon.titan-embed-text-v1\"\n",
    "\n",
    "    try:\n",
    "        print_model_details(wrapper.get_foundation_model(model_id))\n",
    "    except ClientError:\n",
    "        logger.exception(f\"Couldn't get foundation model {model_id}.\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "197fdf1e-f0cb-4fd1-a89c-6ba7296176da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:32:45 AM Got 45 foundation models.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------\n",
      "Welcome to the Amazon Bedrock demo.\n",
      "----------------------------------------------------------------------------------------\n",
      "Listing the available foundation models.\n",
      "\n",
      "==========================================\n",
      " Model: amazon.titan-tg1-large\n",
      "------------------------------------------\n",
      " Name: Titan Text Large\n",
      " Provider: Amazon\n",
      " Model ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-tg1-large\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['TEXT']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['ON_DEMAND']\n",
      " Response streaming supported: True\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: amazon.titan-image-generator-v1:0\n",
      "------------------------------------------\n",
      " Name: Titan Image Generator G1\n",
      " Provider: Amazon\n",
      " Model ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-image-generator-v1:0\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT', 'IMAGE']\n",
      " Output modalities: ['IMAGE']\n",
      " Supported customizations: ['FINE_TUNING']\n",
      " Supported inference types: ['ON_DEMAND', 'PROVISIONED']\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: amazon.titan-image-generator-v1\n",
      "------------------------------------------\n",
      " Name: Titan Image Generator G1\n",
      " Provider: Amazon\n",
      " Model ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-image-generator-v1\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT', 'IMAGE']\n",
      " Output modalities: ['IMAGE']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['ON_DEMAND']\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: amazon.titan-embed-g1-text-02\n",
      "------------------------------------------\n",
      " Name: Titan Text Embeddings v2\n",
      " Provider: Amazon\n",
      " Model ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-g1-text-02\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['EMBEDDING']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['ON_DEMAND']\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: amazon.titan-text-lite-v1:0:4k\n",
      "------------------------------------------\n",
      " Name: Titan Text G1 - Lite\n",
      " Provider: Amazon\n",
      " Model ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-text-lite-v1:0:4k\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['TEXT']\n",
      " Supported customizations: ['FINE_TUNING', 'CONTINUED_PRE_TRAINING']\n",
      " Supported inference types: ['PROVISIONED']\n",
      " Response streaming supported: True\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: amazon.titan-text-lite-v1\n",
      "------------------------------------------\n",
      " Name: Titan Text G1 - Lite\n",
      " Provider: Amazon\n",
      " Model ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-text-lite-v1\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['TEXT']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['ON_DEMAND']\n",
      " Response streaming supported: True\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: amazon.titan-text-express-v1:0:8k\n",
      "------------------------------------------\n",
      " Name: Titan Text G1 - Express\n",
      " Provider: Amazon\n",
      " Model ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-text-express-v1:0:8k\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['TEXT']\n",
      " Supported customizations: ['FINE_TUNING', 'CONTINUED_PRE_TRAINING']\n",
      " Supported inference types: ['PROVISIONED']\n",
      " Response streaming supported: True\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: amazon.titan-text-express-v1\n",
      "------------------------------------------\n",
      " Name: Titan Text G1 - Express\n",
      " Provider: Amazon\n",
      " Model ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-text-express-v1\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['TEXT']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['ON_DEMAND']\n",
      " Response streaming supported: True\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: amazon.titan-embed-text-v1:2:8k\n",
      "------------------------------------------\n",
      " Name: Titan Embeddings G1 - Text\n",
      " Provider: Amazon\n",
      " Model ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-text-v1:2:8k\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['EMBEDDING']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['PROVISIONED']\n",
      " Response streaming supported: False\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: amazon.titan-embed-text-v1\n",
      "------------------------------------------\n",
      " Name: Titan Embeddings G1 - Text\n",
      " Provider: Amazon\n",
      " Model ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-text-v1\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['EMBEDDING']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['ON_DEMAND']\n",
      " Response streaming supported: False\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: amazon.titan-embed-image-v1:0\n",
      "------------------------------------------\n",
      " Name: Titan Multimodal Embeddings G1\n",
      " Provider: Amazon\n",
      " Model ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-image-v1:0\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT', 'IMAGE']\n",
      " Output modalities: ['EMBEDDING']\n",
      " Supported customizations: ['FINE_TUNING']\n",
      " Supported inference types: ['ON_DEMAND', 'PROVISIONED']\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: amazon.titan-embed-image-v1\n",
      "------------------------------------------\n",
      " Name: Titan Multimodal Embeddings G1\n",
      " Provider: Amazon\n",
      " Model ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-image-v1\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT', 'IMAGE']\n",
      " Output modalities: ['EMBEDDING']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['ON_DEMAND']\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: stability.stable-diffusion-xl\n",
      "------------------------------------------\n",
      " Name: SDXL 0.8\n",
      " Provider: Stability AI\n",
      " Model ARN: arn:aws:bedrock:us-east-1::foundation-model/stability.stable-diffusion-xl\n",
      " Lifecycle status: LEGACY\n",
      " Input modalities: ['TEXT', 'IMAGE']\n",
      " Output modalities: ['IMAGE']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['ON_DEMAND']\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: stability.stable-diffusion-xl-v0\n",
      "------------------------------------------\n",
      " Name: SDXL 0.8\n",
      " Provider: Stability AI\n",
      " Model ARN: arn:aws:bedrock:us-east-1::foundation-model/stability.stable-diffusion-xl-v0\n",
      " Lifecycle status: LEGACY\n",
      " Input modalities: ['TEXT', 'IMAGE']\n",
      " Output modalities: ['IMAGE']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['ON_DEMAND']\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: stability.stable-diffusion-xl-v1:0\n",
      "------------------------------------------\n",
      " Name: SDXL 1.0\n",
      " Provider: Stability AI\n",
      " Model ARN: arn:aws:bedrock:us-east-1::foundation-model/stability.stable-diffusion-xl-v1:0\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT', 'IMAGE']\n",
      " Output modalities: ['IMAGE']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['PROVISIONED']\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: stability.stable-diffusion-xl-v1\n",
      "------------------------------------------\n",
      " Name: SDXL 1.0\n",
      " Provider: Stability AI\n",
      " Model ARN: arn:aws:bedrock:us-east-1::foundation-model/stability.stable-diffusion-xl-v1\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT', 'IMAGE']\n",
      " Output modalities: ['IMAGE']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['ON_DEMAND']\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: ai21.j2-grande-instruct\n",
      "------------------------------------------\n",
      " Name: J2 Grande Instruct\n",
      " Provider: AI21 Labs\n",
      " Model ARN: arn:aws:bedrock:us-east-1::foundation-model/ai21.j2-grande-instruct\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['TEXT']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['ON_DEMAND']\n",
      " Response streaming supported: False\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: ai21.j2-jumbo-instruct\n",
      "------------------------------------------\n",
      " Name: J2 Jumbo Instruct\n",
      " Provider: AI21 Labs\n",
      " Model ARN: arn:aws:bedrock:us-east-1::foundation-model/ai21.j2-jumbo-instruct\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['TEXT']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['ON_DEMAND']\n",
      " Response streaming supported: False\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: ai21.j2-mid\n",
      "------------------------------------------\n",
      " Name: Jurassic-2 Mid\n",
      " Provider: AI21 Labs\n",
      " Model ARN: arn:aws:bedrock:us-east-1::foundation-model/ai21.j2-mid\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['TEXT']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['ON_DEMAND']\n",
      " Response streaming supported: False\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: ai21.j2-mid-v1\n",
      "------------------------------------------\n",
      " Name: Jurassic-2 Mid\n",
      " Provider: AI21 Labs\n",
      " Model ARN: arn:aws:bedrock:us-east-1::foundation-model/ai21.j2-mid-v1\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['TEXT']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['ON_DEMAND']\n",
      " Response streaming supported: False\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: ai21.j2-ultra\n",
      "------------------------------------------\n",
      " Name: Jurassic-2 Ultra\n",
      " Provider: AI21 Labs\n",
      " Model ARN: arn:aws:bedrock:us-east-1::foundation-model/ai21.j2-ultra\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['TEXT']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['ON_DEMAND']\n",
      " Response streaming supported: False\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: ai21.j2-ultra-v1\n",
      "------------------------------------------\n",
      " Name: Jurassic-2 Ultra\n",
      " Provider: AI21 Labs\n",
      " Model ARN: arn:aws:bedrock:us-east-1::foundation-model/ai21.j2-ultra-v1\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['TEXT']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['ON_DEMAND']\n",
      " Response streaming supported: False\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: anthropic.claude-instant-v1:2:100k\n",
      "------------------------------------------\n",
      " Name: Claude Instant\n",
      " Provider: Anthropic\n",
      " Model ARN: arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-instant-v1:2:100k\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['TEXT']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['PROVISIONED']\n",
      " Response streaming supported: True\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: anthropic.claude-instant-v1\n",
      "------------------------------------------\n",
      " Name: Claude Instant\n",
      " Provider: Anthropic\n",
      " Model ARN: arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-instant-v1\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['TEXT']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['ON_DEMAND']\n",
      " Response streaming supported: True\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: anthropic.claude-v2:0:18k\n",
      "------------------------------------------\n",
      " Name: Claude\n",
      " Provider: Anthropic\n",
      " Model ARN: arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2:0:18k\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['TEXT']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['PROVISIONED']\n",
      " Response streaming supported: True\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: anthropic.claude-v2:0:100k\n",
      "------------------------------------------\n",
      " Name: Claude\n",
      " Provider: Anthropic\n",
      " Model ARN: arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2:0:100k\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['TEXT']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['PROVISIONED']\n",
      " Response streaming supported: True\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: anthropic.claude-v2:1:18k\n",
      "------------------------------------------\n",
      " Name: Claude\n",
      " Provider: Anthropic\n",
      " Model ARN: arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2:1:18k\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['TEXT']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['PROVISIONED']\n",
      " Response streaming supported: True\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: anthropic.claude-v2:1:200k\n",
      "------------------------------------------\n",
      " Name: Claude\n",
      " Provider: Anthropic\n",
      " Model ARN: arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2:1:200k\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['TEXT']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['PROVISIONED']\n",
      " Response streaming supported: True\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: anthropic.claude-v2:1\n",
      "------------------------------------------\n",
      " Name: Claude\n",
      " Provider: Anthropic\n",
      " Model ARN: arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2:1\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['TEXT']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['ON_DEMAND']\n",
      " Response streaming supported: True\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: anthropic.claude-v2\n",
      "------------------------------------------\n",
      " Name: Claude\n",
      " Provider: Anthropic\n",
      " Model ARN: arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['TEXT']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['ON_DEMAND']\n",
      " Response streaming supported: True\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: anthropic.claude-3-sonnet-20240229-v1:0\n",
      "------------------------------------------\n",
      " Name: Claude 3 Sonnet\n",
      " Provider: Anthropic\n",
      " Model ARN: arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-sonnet-20240229-v1:0\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT', 'IMAGE']\n",
      " Output modalities: ['TEXT']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['ON_DEMAND']\n",
      " Response streaming supported: True\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: cohere.command-text-v14:7:4k\n",
      "------------------------------------------\n",
      " Name: Command\n",
      " Provider: Cohere\n",
      " Model ARN: arn:aws:bedrock:us-east-1::foundation-model/cohere.command-text-v14:7:4k\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['TEXT']\n",
      " Supported customizations: ['FINE_TUNING']\n",
      " Supported inference types: ['PROVISIONED']\n",
      " Response streaming supported: True\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: cohere.command-text-v14\n",
      "------------------------------------------\n",
      " Name: Command\n",
      " Provider: Cohere\n",
      " Model ARN: arn:aws:bedrock:us-east-1::foundation-model/cohere.command-text-v14\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['TEXT']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['ON_DEMAND']\n",
      " Response streaming supported: True\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: cohere.command-light-text-v14:7:4k\n",
      "------------------------------------------\n",
      " Name: Command Light\n",
      " Provider: Cohere\n",
      " Model ARN: arn:aws:bedrock:us-east-1::foundation-model/cohere.command-light-text-v14:7:4k\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['TEXT']\n",
      " Supported customizations: ['FINE_TUNING']\n",
      " Supported inference types: ['PROVISIONED']\n",
      " Response streaming supported: True\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: cohere.command-light-text-v14\n",
      "------------------------------------------\n",
      " Name: Command Light\n",
      " Provider: Cohere\n",
      " Model ARN: arn:aws:bedrock:us-east-1::foundation-model/cohere.command-light-text-v14\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['TEXT']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['ON_DEMAND']\n",
      " Response streaming supported: True\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: cohere.embed-english-v3\n",
      "------------------------------------------\n",
      " Name: Embed English\n",
      " Provider: Cohere\n",
      " Model ARN: arn:aws:bedrock:us-east-1::foundation-model/cohere.embed-english-v3\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['EMBEDDING']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['ON_DEMAND']\n",
      " Response streaming supported: False\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: cohere.embed-multilingual-v3\n",
      "------------------------------------------\n",
      " Name: Embed Multilingual\n",
      " Provider: Cohere\n",
      " Model ARN: arn:aws:bedrock:us-east-1::foundation-model/cohere.embed-multilingual-v3\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['EMBEDDING']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['ON_DEMAND']\n",
      " Response streaming supported: False\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: meta.llama2-13b-chat-v1:0:4k\n",
      "------------------------------------------\n",
      " Name: Llama 2 Chat 13B\n",
      " Provider: Meta\n",
      " Model ARN: arn:aws:bedrock:us-east-1::foundation-model/meta.llama2-13b-chat-v1:0:4k\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['TEXT']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['PROVISIONED']\n",
      " Response streaming supported: True\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: meta.llama2-13b-chat-v1\n",
      "------------------------------------------\n",
      " Name: Llama 2 Chat 13B\n",
      " Provider: Meta\n",
      " Model ARN: arn:aws:bedrock:us-east-1::foundation-model/meta.llama2-13b-chat-v1\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['TEXT']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['ON_DEMAND']\n",
      " Response streaming supported: True\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: meta.llama2-70b-chat-v1:0:4k\n",
      "------------------------------------------\n",
      " Name: Llama 2 Chat 70B\n",
      " Provider: Meta\n",
      " Model ARN: arn:aws:bedrock:us-east-1::foundation-model/meta.llama2-70b-chat-v1:0:4k\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['TEXT']\n",
      " Supported customizations: []\n",
      " Supported inference types: []\n",
      " Response streaming supported: True\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: meta.llama2-70b-chat-v1\n",
      "------------------------------------------\n",
      " Name: Llama 2 Chat 70B\n",
      " Provider: Meta\n",
      " Model ARN: arn:aws:bedrock:us-east-1::foundation-model/meta.llama2-70b-chat-v1\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['TEXT']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['ON_DEMAND']\n",
      " Response streaming supported: True\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: meta.llama2-13b-v1:0:4k\n",
      "------------------------------------------\n",
      " Name: Llama 2 13B\n",
      " Provider: Meta\n",
      " Model ARN: arn:aws:bedrock:us-east-1::foundation-model/meta.llama2-13b-v1:0:4k\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['TEXT']\n",
      " Supported customizations: ['FINE_TUNING']\n",
      " Supported inference types: []\n",
      " Response streaming supported: True\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: meta.llama2-13b-v1\n",
      "------------------------------------------\n",
      " Name: Llama 2 13B\n",
      " Provider: Meta\n",
      " Model ARN: arn:aws:bedrock:us-east-1::foundation-model/meta.llama2-13b-v1\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['TEXT']\n",
      " Supported customizations: []\n",
      " Supported inference types: []\n",
      " Response streaming supported: True\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: meta.llama2-70b-v1:0:4k\n",
      "------------------------------------------\n",
      " Name: Llama 2 70B\n",
      " Provider: Meta\n",
      " Model ARN: arn:aws:bedrock:us-east-1::foundation-model/meta.llama2-70b-v1:0:4k\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['TEXT']\n",
      " Supported customizations: ['FINE_TUNING']\n",
      " Supported inference types: []\n",
      " Response streaming supported: True\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: meta.llama2-70b-v1\n",
      "------------------------------------------\n",
      " Name: Llama 2 70B\n",
      " Provider: Meta\n",
      " Model ARN: arn:aws:bedrock:us-east-1::foundation-model/meta.llama2-70b-v1\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['TEXT']\n",
      " Supported customizations: []\n",
      " Supported inference types: []\n",
      " Response streaming supported: True\n",
      "==========================================\n",
      "Getting the details of an individual foundation model.\n",
      "\n",
      "==========================================\n",
      " Model: amazon.titan-embed-text-v1\n",
      "------------------------------------------\n",
      " Name: Titan Embeddings G1 - Text\n",
      " Provider: Amazon\n",
      " Model ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-text-v1\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['EMBEDDING']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['ON_DEMAND']\n",
      " Response streaming supported: False\n",
      "==========================================\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "from utils import bedrock\n",
    "from utils.BedrockWrapper import BedrockWrapper\n",
    "from utils.GamePlayer import GamePlayer\n",
    "from utils.GameAssistant import GameAssistant\n",
    "from utils.GameMaster import GameMaster\n",
    "from utils.PeTemplates import *\n",
    "from utils import ParseJson, print_ww, Print, Info, Debug, Warn, Error\n",
    "from utils import print_model_details\n",
    "        \n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "usage_demo()\n",
    "#boto3_bedrock = bedrock.get_bedrock_client()\n",
    "\n",
    "#listModels = bedrock.list_foundation_models(byProvider='meta')\n",
    "\n",
    "# print_ww(\"hello\")\n",
    "# Info(\"hello\")\n",
    "\n",
    "# GA = GameAssistant(template_assistant_role, 1000)\n",
    "# print(GA.agent.prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ca9a03-5f1f-46fc-915a-0fa6d0801335",
   "metadata": {},
   "source": [
    "## Test Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0576123a-855f-4322-9770-d8d1504b0898",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def find_most_frequent(arr):\n",
    "  freq = Counter(arr)\n",
    "  max_count = max(freq.values())\n",
    "  \n",
    "  return [k for k, v in freq.items() if v == max_count]\n",
    "\n",
    "vote_names = ['p1','p1','p2','p2','p3','p5','p4','p4']\n",
    "AA = Counter(vote_names)\n",
    "print(AA.most_common())\n",
    "\n",
    "print(find_most_frequent(vote_names))\n",
    "\n",
    "aa = []\n",
    "\n",
    "if len(aa) != 1:\n",
    "    print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77c9faaf-0fcc-4389-bb51-1d93031b93bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['query'] partial_variables={'format_instructions': 'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"setup\": {\"title\": \"Setup\", \"description\": \"question to set up a joke\", \"type\": \"string\"}, \"punchline\": {\"title\": \"Punchline\", \"description\": \"answer to resolve the joke\", \"type\": \"string\"}}, \"required\": [\"setup\", \"punchline\"]}\\n```'} template='Answer the user query.\\n{format_instructions}\\n{query}\\n'\n",
      " Here is a joke formatted to the given JSON schema:\n",
      "\n",
      "```json\n",
      "{\"setup\": \"Why can't a bicycle stand on its own?\", \"punchline\": \"It's too tired!\"}\n",
      "```"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Joke(setup=\"Why can't a bicycle stand on its own?\", punchline=\"It's too tired!\")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.PeTemplates import *\n",
    "from langchain.agents import tool\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
    "\n",
    "# Define your desired data structure.\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "    # You can add custom validation logic easily with Pydantic.\n",
    "    @validator(\"setup\")\n",
    "    def question_ends_with_question_mark(cls, field):\n",
    "        if field[-1] != \"?\":\n",
    "            raise ValueError(\"Badly formed question!\")\n",
    "        return field\n",
    "    \n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = PydanticOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "print(prompt)\n",
    "\n",
    "model = claude3_Sonnet\n",
    "# And a query intended to prompt a language model to populate the data structure.\n",
    "prompt_and_model = prompt | model\n",
    "output = prompt_and_model.invoke({\"query\": \"Tell me a joke.\"})\n",
    "parser.invoke(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898dab35-0dd0-49ee-bf88-b795a73cc607",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.CustomTools import *\n",
    "from utils.PeTemplates import *\n",
    "from langchain.agents import tool\n",
    "\n",
    "# - (): WolfVote : target=\n",
    "# - (): ProphetCheck : target=\n",
    "# - (, ): PlayerDoubt : target= \n",
    "# - : PlayerVote : target= \n",
    "# - : Debate : content=/ \n",
    "# - : GetAllPlayersName :  \n",
    "# - : DeathWords : content=\n",
    "# - : Pass :  \n",
    "# - : Pass :  \n",
    "\n",
    "@tool\n",
    "def WolfVote(target: str) -> str:\n",
    "    \"\"\"()\"\"\"\n",
    "    return \"WolfVote\"\n",
    "\n",
    "@tool\n",
    "def ProphetCheck(target: str) -> str:\n",
    "    \"\"\"()\"\"\"\n",
    "    return \"ProphetCheck\"\n",
    "\n",
    "@tool\n",
    "def PlayerDoubt(target: str) -> str:\n",
    "    \"\"\"(, )\"\"\"\n",
    "    return \"PlayerDoubt\"\n",
    "\n",
    "@tool\n",
    "def PlayerVote(target: str) -> str:\n",
    "    \"\"\"\"\"\"\n",
    "    return \"PlayerVote\"\n",
    "\n",
    "@tool\n",
    "def Debate(target: str) -> str:\n",
    "    \"\"\"\"\"\"\n",
    "    return \"Debate\"\n",
    "\n",
    "@tool\n",
    "def GetAllPlayersName(target: str) -> str:\n",
    "    \"\"\"\"\"\"\n",
    "    return \"GetAllPlayersName\"\n",
    "\n",
    "@tool\n",
    "def DeathWords(content: str) -> str:\n",
    "    \"\"\"\"\"\"\n",
    "    return \"DeathWords\"\n",
    "\n",
    "@tool\n",
    "def Pass(content: str) -> str:\n",
    "    \"\"\",\"\"\"\n",
    "    return \"Pass\"\n",
    "\n",
    " \n",
    "# print(f\"search.name:{search.name}\")\n",
    "# print(f\"search.description:{search.description}\")\n",
    "# print(f\"search.args:{search.args}\")\n",
    "\n",
    "# Define a list of tools\n",
    "tools = [\n",
    "    Tool(\n",
    "        name = \"WolfVote\",\n",
    "        func=WolfVote.run,\n",
    "        description=\"()\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name = \"ProphetCheck\",\n",
    "        func=ProphetCheck.run,\n",
    "        description=\"()\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name = \"PlayerDoubt\",\n",
    "        func=PlayerDoubt.run,\n",
    "        description=\"(, )\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name = \"PlayerVote\",\n",
    "        func=PlayerVote.run,\n",
    "        description=\"\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name = \"Pass\",\n",
    "        func=Pass.run,\n",
    "        description=\",\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# Using tools, the LLM chain and output_parser to make an agent\n",
    "tool_names = [tool.name for tool in tools]\n",
    "\n",
    "prompt = CustomPromptTemplate(\n",
    "    template=template_werewolf_role,\n",
    "    tools=tools,\n",
    "    # This omits the `agent_scratchpad`, `tools`, and `tool_names` variables because those are generated dynamically\n",
    "    # This includes the `intermediate_steps` variable because that is needed\n",
    "    input_variables=[\"input\", \"intermediate_steps\", \"history\", 'agent_scratchpad', 'tools', 'tool_names']\n",
    ")\n",
    "#print(prompt)\n",
    "# output_parser = CustomOutputParser()\n",
    "\n",
    "llm = claude_instant_llm\n",
    "\n",
    "# LLM chain consisting of the LLM and a prompt\n",
    "# llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "agent = create_structured_chat_agent(llm, tools, prompt)\n",
    "\n",
    "# agent = LLMSingleActionAgent(\n",
    "#     llm_chain=llm_chain, \n",
    "#     output_parser=output_parser,\n",
    "#     # We use \"Observation\" as our stop sequence so it will stop when it receives Tool output\n",
    "#     # If you change your prompt template you'll need to adjust this as well\n",
    "#     stop=[\"\\nObservation:\"], \n",
    "#     allowed_tools=tool_names\n",
    "# )\n",
    "\n",
    "# Initiate the agent that will respond to our queries\n",
    "# Set verbose=True to share the CoT reasoning the LLM goes through\n",
    "memory = ConversationBufferWindowMemory(k=2)\n",
    "agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, memory=memory, verbose=False)\n",
    "\n",
    "agent_executor.invoke({\"input\":\"\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a82dcee-a14c-4bee-927a-ea230129b227",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:50:59 AM \t===== P1:,P2:,P3:,P4:,P5:,P6:,P7:,P8: ResetGame =====\n",
      "03/05/2024 02:50:59 AM P1 is \n",
      "03/05/2024 02:50:59 AM P2 is \n",
      "03/05/2024 02:50:59 AM P3 is \n",
      "03/05/2024 02:50:59 AM P4 is \n",
      "03/05/2024 02:50:59 AM P5 is \n",
      "03/05/2024 02:50:59 AM P6 is \n",
      "03/05/2024 02:50:59 AM P7 is \n",
      "03/05/2024 02:50:59 AM P8 is \n",
      "03/05/2024 02:50:59 AM \t===== P1:,P2:,P3:,P4:,P5:,P6:,P7:,P8: RunGame =====\n",
      "03/05/2024 02:50:59 AM \t===== input_tokens: 0 output_tokens 0 ======\n",
      "03/05/2024 02:50:59 AM \t===== elapsed_time: 0.007664203643798828 ======\n",
      "03/05/2024 02:50:59 AM \t===== NIGHT 1 PreAction ======\n",
      "03/05/2024 02:50:59 AM \t===== NIGHT 1 DoAction ======\n",
      "03/05/2024 02:50:59 AM \t\t===== DoMemory NIGHT 1 P1 ======\n",
      "03/05/2024 02:50:59 AM \t\t===== DoReflect NIGHT 1 P1 ======\n",
      "03/05/2024 02:50:59 AM \t\t===== DoAnswer NIGHT 1 P1 ======\n",
      "03/05/2024 02:50:59 AM \tQUESTION: NIGHT 1,P1()..:P1:,P2:,P3:,P4:,P5:,P6:,P7:,P8:().1?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\"action\":\"ProphetCheck\",\"target\":\"P3\"}\n",
      "\n",
      ":\n",
      ",,\n",
      ",P3,\n",
      ",,,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:51:02 AM \t\t===== DoAction NIGHT 1 P1 ======\n",
      "03/05/2024 02:51:02 AM [P1NIGHT 1, :{'action': 'ProphetCheck', 'target': 'P3'}]P3:\n",
      "03/05/2024 02:51:02 AM \n",
      " [ROUND ACTION]={'time': 'NIGHT 1', 'player': 'P1', 'status': 1, 'role': '', 'character': '', 'response': ['{\"action\":\"ProphetCheck\",\"target\":\"P3\"}']}\n",
      "\n",
      "03/05/2024 02:51:02 AM \t\t===== DoMemory NIGHT 1 P3 ======\n",
      "03/05/2024 02:51:02 AM \t\t===== DoReflect NIGHT 1 P3 ======\n",
      "03/05/2024 02:51:02 AM \t\t===== DoAnswer NIGHT 1 P3 ======\n",
      "03/05/2024 02:51:02 AM \tQUESTION: NIGHT 1,P3(,:P3,P6).:P1:,P2:,P3:,P4:,P5:,P6:,P7:,P8:().1?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\"action\":\"WolfVote\",\"target\":\"P5\"}\n",
      "\n",
      ":\n",
      ",,P5,,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:51:05 AM \t\t===== DoAction NIGHT 1 P3 ======\n",
      "03/05/2024 02:51:05 AM \n",
      " [ROUND ACTION]={'time': 'NIGHT 1', 'player': 'P3', 'status': 1, 'role': '', 'character': '', 'response': ['{\"action\":\"WolfVote\",\"target\":\"P5\"}']}\n",
      "\n",
      "03/05/2024 02:51:05 AM \t\t===== DoMemory NIGHT 1 P6 ======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ,P3P5"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:51:06 AM \t\t===== DoReflect NIGHT 1 P6 ======\n",
      "03/05/2024 02:51:06 AM \t\t===== DoAnswer NIGHT 1 P6 ======\n",
      "03/05/2024 02:51:06 AM \tQUESTION: NIGHT 1,P6(,:P3,P6).:P1:,P2:,P3:,P4:,P5:,P6:,P7:,P8:()...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\"action\":\"Debate\",\"content\":\",P5P3,,,\"}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:51:09 AM \t\t===== DoAnswer NIGHT 1 P6 ======\n",
      "03/05/2024 02:51:09 AM \tQUESTION: NIGHT 1,P6(,:P3,P6).:P1:,P2:,P3:,P4:,P5:,P6:,P7:,P8:().1?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\"action\":\"WolfVote\",\"target\":\"P5\"}\n",
      "\n",
      ":,P5,,P3,P5"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:51:12 AM \t\t===== DoAction NIGHT 1 P6 ======\n",
      "03/05/2024 02:51:12 AM \n",
      " [ROUND ACTION]={'time': 'NIGHT 1', 'player': 'P6', 'status': 1, 'role': '', 'character': '', 'response': ['{\"action\":\"WolfVote\",\"target\":\"P5\"}']}\n",
      "\n",
      "03/05/2024 02:51:12 AM \t===== NIGHT 1 PostAction ======\n",
      "03/05/2024 02:51:12 AM \t [wolf_votes]: ['P5'], [player_vote_name]: Counter({'P5': 2})\n",
      "03/05/2024 02:51:12 AM \n",
      " [WOLF VOTE]={'time': 'NIGHT 1', 'player': 'P5', 'status': 0, 'role': '', 'character': '', 'response': 'P5NIGHT 1'}\n",
      "\n",
      "03/05/2024 02:51:12 AM . :P1:,P2:,P3:,P4:,P5:,P6:,P7:,P8:\n",
      "03/05/2024 02:51:12 AM \t===== input_tokens: 17031 output_tokens 420 ======\n",
      "03/05/2024 02:51:12 AM \t===== elapsed_time: 12.929008722305298 ======\n",
      "03/05/2024 02:51:12 AM \t===== DAY 2 PreAction ======\n",
      "03/05/2024 02:51:12 AM \t\t===== DoMemory DAY 2 P5 ======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ,P5"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:51:13 AM \t\t===== DoReflect DAY 2 P5 ======\n",
      "03/05/2024 02:51:13 AM \t\t===== DoAnswer DAY 2 P5 ======\n",
      "03/05/2024 02:51:13 AM \tQUESTION: DAY 2,P5()..:P1:,P2:,P3:,P4:,P5:,P6:,P7:,P8:()...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\"action\":\"Debate\",\"content\":\"P5,,P5,,P3,P3,P3,P3\"}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:51:17 AM \t\t===== DoAnswer DAY 2 P5 ======\n",
      "03/05/2024 02:51:17 AM \tQUESTION: DAY 2,P5()..:P1:,P2:,P3:,P4:,P5:,P6:,P7:,P8:().2,?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\"action\":\"DeathWords\",\"content\":\"P5,P3,P1P2P4P6P7P8,P3,P3\"}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:51:21 AM \t\t===== DoAction DAY 2 P5 ======\n",
      "03/05/2024 02:51:21 AM \n",
      " [ROUND ACTION]={'time': 'DAY 2', 'player': 'P5', 'status': 0, 'role': '', 'character': '', 'response': ['{\"action\":\"DeathWords\",\"content\":\"P5,P3,P1P2P4P6P7P8,P3,P3\"}']}\n",
      "\n",
      "03/05/2024 02:51:21 AM \t===== DAY 2 DoAction ======\n",
      "03/05/2024 02:51:21 AM \t\t===== DoMemory DAY 2 P1 ======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " :P1P2P6P7P8,P3P5P5P3,P1P3"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:51:24 AM \t\t===== DoReflect DAY 2 P1 ======\n",
      "03/05/2024 02:51:24 AM \t\t===== DoAnswer DAY 2 P1 ======\n",
      "03/05/2024 02:51:24 AM \tQUESTION: DAY 2,P1()..:P1:,P2:,P3:,P4:,P5:,P6:,P7:,P8:()...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\"reflections\":\",P3,,P5P3,,P5,P2P4P6P7P8\"}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:51:27 AM \t\t===== DoAnswer DAY 2 P1 ======\n",
      "03/05/2024 02:51:27 AM \tQUESTION: DAY 2,P1()..:P1:,P2:,P3:,P4:,P5:,P6:,P7:,P8:().2?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\"reflections\":\"P5,P3,P2P4P6P7P8P3,\"}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:51:30 AM \t\t===== DoAction DAY 2 P1 ======\n",
      "03/05/2024 02:51:30 AM \n",
      " [ROUND ACTION]={'time': 'DAY 2', 'player': 'P1', 'status': 1, 'role': '', 'character': '', 'response': ['{\"reflections\":\"P5,P3,P2P4P6P7P8P3,\"}']}\n",
      "\n",
      "03/05/2024 02:51:30 AM \t\t===== DoMemory DAY 2 P2 ======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ,P5P3,P3"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:51:32 AM \t\t===== DoReflect DAY 2 P2 ======\n",
      "03/05/2024 02:51:32 AM \t\t===== DoAnswer DAY 2 P2 ======\n",
      "03/05/2024 02:51:32 AM \tQUESTION: DAY 2,P2()..:P1:,P2:,P3:,P4:,P5:,P6:,P7:,P8:()...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\"reflections\":\"P5P3,P3,P1\"}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:51:34 AM \t\t===== DoAnswer DAY 2 P2 ======\n",
      "03/05/2024 02:51:34 AM \tQUESTION: DAY 2,P2()..:P1:,P2:,P3:,P4:,P5:,P6:,P7:,P8:().2?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\"reflections\":\"P5P3,,\"}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:51:36 AM \t\t===== DoAction DAY 2 P2 ======\n",
      "03/05/2024 02:51:36 AM \n",
      " [ROUND ACTION]={'time': 'DAY 2', 'player': 'P2', 'status': 1, 'role': '', 'character': '', 'response': ['{\"reflections\":\"P5P3,,\"}']}\n",
      "\n",
      "03/05/2024 02:51:36 AM \t\t===== DoMemory DAY 2 P3 ======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " P5P3,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:51:38 AM \t\t===== DoReflect DAY 2 P3 ======\n",
      "03/05/2024 02:51:38 AM \t\t===== DoAnswer DAY 2 P3 ======\n",
      "03/05/2024 02:51:38 AM \tQUESTION: DAY 2,P3(,:P3,P6).:P1:,P2:,P3:,P4:,P5:,P6:,P7:,P8:()...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\"action\":\"Debate\",\"content\":\"P5P3,,P5P5,,\"}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:51:40 AM \t\t===== DoAnswer DAY 2 P3 ======\n",
      "03/05/2024 02:51:40 AM \tQUESTION: DAY 2,P3(,:P3,P6).:P1:,P2:,P3:,P4:,P5:,P6:,P7:,P8:().2?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\"action\":\"Debate\",\"content\":\"P5P3,,P5,\"}\n",
      "\n",
      ":\n",
      "P5,,,P5,,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:51:44 AM \t\t===== DoAction DAY 2 P3 ======\n",
      "03/05/2024 02:51:44 AM \n",
      " [ROUND ACTION]={'time': 'DAY 2', 'player': 'P3', 'status': 1, 'role': '', 'character': '', 'response': ['{\"action\":\"Debate\",\"content\":\"P5P3,,P5,\"}']}\n",
      "\n",
      "03/05/2024 02:51:44 AM \t\t===== DoMemory DAY 2 P4 ======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " P5,P5P3,P3,P5P1P2P4P6P7P8"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:51:47 AM \t\t===== DoReflect DAY 2 P4 ======\n",
      "03/05/2024 02:51:47 AM \t\t===== DoAnswer DAY 2 P4 ======\n",
      "03/05/2024 02:51:47 AM \tQUESTION: DAY 2,P4()..:P1:,P2:,P3:,P4:,P5:,P6:,P7:,P8:()...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\"action\":\"Debate\",\"content\":\"P5P3,P3P5,P3,P5,P5,,\"}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:51:51 AM \t\t===== DoAnswer DAY 2 P4 ======\n",
      "03/05/2024 02:51:51 AM \tQUESTION: DAY 2,P4()..:P1:,P2:,P3:,P4:,P5:,P6:,P7:,P8:().2?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\"action\":\"Debate\",\"content\":\"P5P3,P3P5,P3,P5,P5,,,\"}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:51:54 AM \t\t===== DoAction DAY 2 P4 ======\n",
      "03/05/2024 02:51:54 AM \n",
      " [ROUND ACTION]={'time': 'DAY 2', 'player': 'P4', 'status': 1, 'role': '', 'character': '', 'response': ['{\"action\":\"Debate\",\"content\":\"P5P3,P3P5,P3,P5,P5,,,\"}']}\n",
      "\n",
      "03/05/2024 02:51:54 AM \t\t===== DoMemory DAY 2 P6 ======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ,P5P5P3,P3P5,P4P3,,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:51:58 AM \t\t===== DoReflect DAY 2 P6 ======\n",
      "03/05/2024 02:51:58 AM \t\t===== DoAnswer DAY 2 P6 ======\n",
      "03/05/2024 02:51:58 AM \tQUESTION: DAY 2,P6(,:P3,P6).:P1:,P2:,P3:,P4:,P5:,P6:,P7:,P8:()...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\"action\":\"Debate\",\"content\":\"P5P3,,P3,P4,,\"}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:52:02 AM \t\t===== DoAnswer DAY 2 P6 ======\n",
      "03/05/2024 02:52:02 AM \tQUESTION: DAY 2,P6(,:P3,P6).:P1:,P2:,P3:,P4:,P5:,P6:,P7:,P8:().2?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\"action\":\"Debate\",\"content\":\"P5P3,P4P3,,,,\"}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:52:04 AM \t\t===== DoAction DAY 2 P6 ======\n",
      "03/05/2024 02:52:04 AM \n",
      " [ROUND ACTION]={'time': 'DAY 2', 'player': 'P6', 'status': 1, 'role': '', 'character': '', 'response': ['{\"action\":\"Debate\",\"content\":\"P5P3,P4P3,,,,\"}']}\n",
      "\n",
      "03/05/2024 02:52:04 AM \t\t===== DoMemory DAY 2 P7 ======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " :P1~P8P5NIGHT 1P5P3P3P5P4P5P6"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:52:07 AM \t\t===== DoReflect DAY 2 P7 ======\n",
      "03/05/2024 02:52:07 AM \t\t===== DoAnswer DAY 2 P7 ======\n",
      "03/05/2024 02:52:07 AM \tQUESTION: DAY 2,P7()..:P1:,P2:,P3:,P4:,P5:,P6:,P7:,P8:()...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\"action\":\"Debate\",\"content\":\"P5P3,P3P5,P4P5,,P3,P6,,P3P6\"}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:52:10 AM \t\t===== DoAnswer DAY 2 P7 ======\n",
      "03/05/2024 02:52:10 AM \tQUESTION: DAY 2,P7()..:P1:,P2:,P3:,P4:,P5:,P6:,P7:,P8:().2?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\"action\":\"Debate\",\"content\":\"P5P3,P3P5,P4P5,,P3P6,,P3P6,\"}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:52:12 AM \t\t===== DoAction DAY 2 P7 ======\n",
      "03/05/2024 02:52:12 AM \n",
      " [ROUND ACTION]={'time': 'DAY 2', 'player': 'P7', 'status': 1, 'role': '', 'character': '', 'response': ['{\"action\":\"Debate\",\"content\":\"P5P3,P3P5,P4P5,,P3P6,,P3P6,\"}']}\n",
      "\n",
      "03/05/2024 02:52:12 AM \t\t===== DoMemory DAY 2 P8 ======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " :6,P5P3,,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:52:14 AM \t\t===== DoReflect DAY 2 P8 ======\n",
      "03/05/2024 02:52:14 AM \t\t===== DoAnswer DAY 2 P8 ======\n",
      "03/05/2024 02:52:14 AM \tQUESTION: DAY 2,P8()..:P1:,P2:,P3:,P4:,P5:,P6:,P7:,P8:()...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\"reflections\":\"- P3,,- P3,- ,,\"}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:52:17 AM \t\t===== DoAnswer DAY 2 P8 ======\n",
      "03/05/2024 02:52:17 AM \tQUESTION: DAY 2,P8()..:P1:,P2:,P3:,P4:,P5:,P6:,P7:,P8:().2?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\"action\":\"Debate\",\"content\":\"P3,,,\"}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:52:20 AM \t\t===== DoAction DAY 2 P8 ======\n",
      "03/05/2024 02:52:20 AM \n",
      " [ROUND ACTION]={'time': 'DAY 2', 'player': 'P8', 'status': 1, 'role': '', 'character': '', 'response': ['{\"action\":\"Debate\",\"content\":\"P3,,,\"}']}\n",
      "\n",
      "03/05/2024 02:52:20 AM \t===== DAY 2 PostAction ======\n",
      "03/05/2024 02:52:20 AM \t\t===== DoMemory DAY 2 P1 ======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " :P1P2P6P7P8,P3P5P5P3,P1P3"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:52:24 AM \t\t===== DoReflect DAY 2 P1 ======\n",
      "03/05/2024 02:52:24 AM \t\t===== DoAnswer DAY 2 P1 ======\n",
      "03/05/2024 02:52:24 AM \tQUESTION: DAY 2,P1()..:P1:,P2:,P3:,P4:,P5:,P6:,P7:,P8:()...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " <reflections>\n",
      ",P3,P2P4P6P7P8\n",
      "P3,\n",
      ",\n",
      "</reflections>\n",
      "\n",
      "{\"action\":\"PlayerVote\",\"target\":\"P3\"}\n",
      "\n",
      ":\n",
      ",P3P3,\n",
      ",P3,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:52:28 AM \t\t===== DoAnswer DAY 2 P1 ======\n",
      "03/05/2024 02:52:28 AM \tQUESTION: DAY 2,P1()..:P1:,P2:,P3:,P4:,P5:,P6:,P7:,P8:().2?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " <reflections>\n",
      "P3,,\n",
      "</reflections>\n",
      "\n",
      "{\"action\":\"PlayerVote\",\"target\":\"P4\"}\n",
      "\n",
      ":\n",
      "P4,P4,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:52:32 AM \t\t===== DoAction DAY 2 P1 ======\n",
      "03/05/2024 02:52:32 AM \n",
      " [ROUND ACTION]={'time': 'DAY 2', 'player': 'P1', 'status': 1, 'role': '', 'character': '', 'response': ['{\"action\":\"PlayerVote\",\"target\":\"P4\"}']}\n",
      "\n",
      "03/05/2024 02:52:32 AM \t\t===== DoMemory DAY 2 P2 ======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " P5P3,P4P3P5P6P8,P7P3P6P1P4"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:52:35 AM \t\t===== DoReflect DAY 2 P2 ======\n",
      "03/05/2024 02:52:35 AM \t\t===== DoAnswer DAY 2 P2 ======\n",
      "03/05/2024 02:52:35 AM \tQUESTION: DAY 2,P2()..:P1:,P2:,P3:,P4:,P5:,P6:,P7:,P8:()...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\"reflections\":\"P5P3,P3,P1P4,\"}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:52:38 AM \t\t===== DoAnswer DAY 2 P2 ======\n",
      "03/05/2024 02:52:38 AM \tQUESTION: DAY 2,P2()..:P1:,P2:,P3:,P4:,P5:,P6:,P7:,P8:().2?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\"reflections\":\"P5P3,P4,P3,P1P4P6P8,P7P3P6,P7P3P4P1P7,\"}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:52:41 AM \t\t===== DoAction DAY 2 P2 ======\n",
      "03/05/2024 02:52:41 AM \n",
      " [ROUND ACTION]={'time': 'DAY 2', 'player': 'P2', 'status': 1, 'role': '', 'character': '', 'response': ['{\"reflections\":\"P5P3,P4,P3,P1P4P6P8,P7P3P6,P7P3P4P1P7,\"}']}\n",
      "\n",
      "03/05/2024 02:52:41 AM \t\t===== DoMemory DAY 2 P3 ======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " P5P3,P3P5,P4P5,P6P7P8P1P4"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:52:44 AM \t\t===== DoReflect DAY 2 P3 ======\n",
      "03/05/2024 02:52:44 AM \t\t===== DoAnswer DAY 2 P3 ======\n",
      "03/05/2024 02:52:44 AM \tQUESTION: DAY 2,P3(,:P3,P6).:P1:,P2:,P3:,P4:,P5:,P6:,P7:,P8:()...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\"action\":\"Debate\",\"content\":\"P5,,,P5,P5,\"}\n",
      "\n",
      ":\n",
      "P5,,,P5,,P5,,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:52:49 AM \t\t===== DoAnswer DAY 2 P3 ======\n",
      "03/05/2024 02:52:49 AM \tQUESTION: DAY 2,P3(,:P3,P6).:P1:,P2:,P3:,P4:,P5:,P6:,P7:,P8:().2?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\"action\":\"PlayerVote\",\"target\":\"P4\"}\n",
      "\n",
      ":\n",
      "P5P3,,P4P5,P4,P5P4,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:52:54 AM \t\t===== DoAction DAY 2 P3 ======\n",
      "03/05/2024 02:52:54 AM \n",
      " [ROUND ACTION]={'time': 'DAY 2', 'player': 'P3', 'status': 1, 'role': '', 'character': '', 'response': ['{\"action\":\"PlayerVote\",\"target\":\"P4\"}']}\n",
      "\n",
      "03/05/2024 02:52:54 AM \t\t===== DoMemory DAY 2 P4 ======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " P5,P3P3P5,P4P5,P6,P7P3P6,P8P1P3P4"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:52:57 AM \t\t===== DoReflect DAY 2 P4 ======\n",
      "03/05/2024 02:52:57 AM \t\t===== DoAnswer DAY 2 P4 ======\n",
      "03/05/2024 02:52:57 AM \tQUESTION: DAY 2,P4()..:P1:,P2:,P3:,P4:,P5:,P6:,P7:,P8:()...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\"action\":\"Debate\",\"content\":\"P5P3,P3P5,P3,P5,,,\"}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:53:00 AM \t\t===== DoAnswer DAY 2 P4 ======\n",
      "03/05/2024 02:53:00 AM \tQUESTION: DAY 2,P4()..:P1:,P2:,P3:,P4:,P5:,P6:,P7:,P8:().2?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\"action\":\"PlayerVote\",\"target\":\"P3\"}\n",
      "\n",
      "<reflections>\n",
      "- P5P3,P3P5,\n",
      "- P3,P5,P5\n",
      "- P6P7P3,P3\n",
      "- ,,P3\n",
      "- ,,\n",
      "</reflections>\n",
      "\n",
      "P3,P3,,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:53:06 AM \t\t===== DoAction DAY 2 P4 ======\n",
      "03/05/2024 02:53:06 AM \n",
      " [ROUND ACTION]={'time': 'DAY 2', 'player': 'P4', 'status': 1, 'role': '', 'character': '', 'response': ['{\"action\":\"PlayerVote\",\"target\":\"P3\"}']}\n",
      "\n",
      "03/05/2024 02:53:06 AM \t\t===== DoMemory DAY 2 P6 ======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ,P5P5P3,P3P5,P4P5P3,P6P1P3P4,P4P3"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:53:09 AM \t\t===== DoReflect DAY 2 P6 ======\n",
      "03/05/2024 02:53:09 AM \t\t===== DoAnswer DAY 2 P6 ======\n",
      "03/05/2024 02:53:09 AM \tQUESTION: DAY 2,P6(,:P3,P6).:P1:,P2:,P3:,P4:,P5:,P6:,P7:,P8:()...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\"action\":\"Debate\",\"content\":\"P5P3,P4P3,,,,P3,,\"}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:53:12 AM \t\t===== DoAnswer DAY 2 P6 ======\n",
      "03/05/2024 02:53:12 AM \tQUESTION: DAY 2,P6(,:P3,P6).:P1:,P2:,P3:,P4:,P5:,P6:,P7:,P8:().2?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\"action\":\"PlayerVote\",\"target\":\"P4\"}\n",
      "\n",
      ":P5P3,P4,P3,P3,P4,,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:53:15 AM \t\t===== DoAction DAY 2 P6 ======\n",
      "03/05/2024 02:53:15 AM \n",
      " [ROUND ACTION]={'time': 'DAY 2', 'player': 'P6', 'status': 1, 'role': '', 'character': '', 'response': ['{\"action\":\"PlayerVote\",\"target\":\"P4\"}']}\n",
      "\n",
      "03/05/2024 02:53:15 AM \t\t===== DoMemory DAY 2 P7 ======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " :P1~P8P5NIGHT 1P5P3,P3P5P4P5,P6P7P3P5,P4P6P8P3P1P3P6P4(96)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:53:19 AM \t\t===== DoReflect DAY 2 P7 ======\n",
      "03/05/2024 02:53:19 AM \t\t===== DoAnswer DAY 2 P7 ======\n",
      "03/05/2024 02:53:19 AM \tQUESTION: DAY 2,P7()..:P1:,P2:,P3:,P4:,P5:,P6:,P7:,P8:()...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\"action\":\"Debate\",\"content\":\"P5P3,P3P5,P4P5,,P3P6,,P3P6,\"}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:53:21 AM \t\t===== DoAnswer DAY 2 P7 ======\n",
      "03/05/2024 02:53:21 AM \tQUESTION: DAY 2,P7()..:P1:,P2:,P3:,P4:,P5:,P6:,P7:,P8:().2?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\"action\":\"PlayerVote\",\"target\":\"P3\"}\n",
      "\n",
      "<reflections>\n",
      "- P5P3,P4,\n",
      "- P3,P5,\n",
      "- P6,,\n",
      "- ,P3,P3\n",
      "</reflections>"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:53:26 AM \t\t===== DoAction DAY 2 P7 ======\n",
      "03/05/2024 02:53:26 AM \n",
      " [ROUND ACTION]={'time': 'DAY 2', 'player': 'P7', 'status': 1, 'role': '', 'character': '', 'response': ['{\"action\":\"PlayerVote\",\"target\":\"P3\"}']}\n",
      "\n",
      "03/05/2024 02:53:26 AM \t\t===== DoMemory DAY 2 P8 ======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6,P5P3,,,P3P1P3P6P4,P4P7P3"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:53:31 AM \t\t===== DoReflect DAY 2 P8 ======\n",
      "03/05/2024 02:53:31 AM \t\t===== DoAnswer DAY 2 P8 ======\n",
      "03/05/2024 02:53:31 AM \tQUESTION: DAY 2,P8()..:P1:,P2:,P3:,P4:,P5:,P6:,P7:,P8:()...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\"reflections\":\"- P3,,- P1P3P6,- \"}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:53:37 AM \t\t===== DoAnswer DAY 2 P8 ======\n",
      "03/05/2024 02:53:37 AM \tQUESTION: DAY 2,P8()..:P1:,P2:,P3:,P4:,P5:,P6:,P7:,P8:().2?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\"reflections\":\"- P3,,- P1P3P6,- P3,\"}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:53:39 AM \t\t===== DoAction DAY 2 P8 ======\n",
      "03/05/2024 02:53:39 AM \n",
      " [ROUND ACTION]={'time': 'DAY 2', 'player': 'P8', 'status': 1, 'role': '', 'character': '', 'response': ['{\"reflections\":\"- P3,,- P1P3P6,- P3,\"}']}\n",
      "\n",
      "03/05/2024 02:53:39 AM \t [player_votes]: ['P4'], [player_vote_name]: Counter({'P4': 3, 'P3': 2})\n",
      "03/05/2024 02:53:39 AM \n",
      " [PLAYER VOTE]={'time': 'DAY 2', 'player': 'P4', 'status': 0, 'role': '', 'character': '', 'response': 'P4DAY 2'}\n",
      "\n",
      "03/05/2024 02:53:39 AM \t\t===== DoMemory DAY 2 P4 ======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ,P5P3,P3P5,P4P5,P6,P7P3,P8P1P3P4,P4P3,P6P4,P7P3,P4"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:53:43 AM \t\t===== DoReflect DAY 2 P4 ======\n",
      "03/05/2024 02:53:43 AM \t\t===== DoAnswer DAY 2 P4 ======\n",
      "03/05/2024 02:53:43 AM \tQUESTION: DAY 2,P4()..:P1:,P2:,P3:,P4:,P5:,P6:,P7:,P8:()...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " <reflections>\n",
      "- P4,\n",
      "- P5P3,P3P5,\n",
      "- P3,P6P7P3\n",
      "- P3,\n",
      "</reflections>\n",
      "\n",
      "{\"action\":\"Debate\",\"content\":\"P4,P5P3,P3P6P7P3,P3P3,\"}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:53:50 AM \t\t===== DoAnswer DAY 2 P4 ======\n",
      "03/05/2024 02:53:50 AM \tQUESTION: DAY 2,P4()..:P1:,P2:,P3:,P4:,P5:,P6:,P7:,P8:().2,?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " <reflections>\n",
      "- P4,\n",
      "- P5P3,P3P5,\n",
      "- P3,P3\n",
      "</reflections>\n",
      "\n",
      "{\"action\":\"DeathWords\",\"content\":\",,P3,,P3,,,!\"}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:53:55 AM \t\t===== DoAction DAY 2 P4 ======\n",
      "03/05/2024 02:53:55 AM \n",
      " [ROUND ACTION]={'time': 'DAY 2', 'player': 'P4', 'status': 0, 'role': '', 'character': '', 'response': ['{\"action\":\"DeathWords\",\"content\":\",,P3,,P3,,,!\"}']}\n",
      "\n",
      "03/05/2024 02:53:55 AM . :P1:,P2:,P3:,P4:,P5:,P6:,P7:,P8:\n",
      "03/05/2024 02:53:55 AM \t===== NIGHT 2 PreAction ======\n",
      "03/05/2024 02:53:55 AM \t===== NIGHT 2 DoAction ======\n",
      "03/05/2024 02:53:55 AM \t\t===== DoMemory NIGHT 2 P1 ======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " P1P2P6P7P8P5P3,P4P3P4DAY2P4P3P1P3,P3"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:53:58 AM \t\t===== DoReflect NIGHT 2 P1 ======\n",
      "03/05/2024 02:53:58 AM \t\t===== DoAnswer NIGHT 2 P1 ======\n",
      "03/05/2024 02:53:58 AM \tQUESTION: NIGHT 2,P1()..:P1:,P2:,P3:,P4:,P5:,P6:,P7:,P8:()...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " <reflections>\n",
      "P3,P4P5\n",
      ",P2P6P7P8\n",
      "</reflections>\n",
      "\n",
      "{\"action\":\"ProphetCheck\",\"target\":\"P2\"}\n",
      "\n",
      ":\n",
      "P2,\n",
      "P2,;,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:54:02 AM \t\t===== DoAnswer NIGHT 2 P1 ======\n",
      "03/05/2024 02:54:02 AM \tQUESTION: NIGHT 2,P1()..:P1:,P2:,P3:,P4:,P5:,P6:,P7:,P8:().2?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " <reflections>\n",
      "P3,P2P6P7P8\n",
      "</reflections>\n",
      "\n",
      "{\"action\":\"ProphetCheck\",\"target\":\"P2\"}\n",
      "\n",
      ":P2,,P2,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:54:05 AM \t\t===== DoAction NIGHT 2 P1 ======\n",
      "03/05/2024 02:54:05 AM [P1NIGHT 2, :{'action': 'ProphetCheck', 'target': 'P2'}]P2:\n",
      "03/05/2024 02:54:05 AM \n",
      " [ROUND ACTION]={'time': 'NIGHT 2', 'player': 'P1', 'status': 1, 'role': '', 'character': '', 'response': ['{\"action\":\"ProphetCheck\",\"target\":\"P2\"}']}\n",
      "\n",
      "03/05/2024 02:54:05 AM \t\t===== DoMemory NIGHT 2 P3 ======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ,P5P3,P3P5,P4P5P6P7P8,P1~P7P4,P4P3"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:54:08 AM \t\t===== DoReflect NIGHT 2 P3 ======\n",
      "03/05/2024 02:54:08 AM \t\t===== DoAnswer NIGHT 2 P3 ======\n",
      "03/05/2024 02:54:08 AM \tQUESTION: NIGHT 2,P3(,:P3,P6).:P1:,P2:,P3:,P4:,P5:,P6:,P7:,P8:()...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " <reflections>\n",
      "- P4P3,P4\n",
      "- P4,P3\n",
      "- P1,,\n",
      "- P1,\n",
      "</reflections>\n",
      "\n",
      ",,:\n",
      "\n",
      "{\"action\":\"WolfVote\",\"target\":\"P1\"}\n",
      "\n",
      ":P1,P4,P1,P3P4,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:54:16 AM \t\t===== DoAnswer NIGHT 2 P3 ======\n",
      "03/05/2024 02:54:16 AM \tQUESTION: NIGHT 2,P3(,:P3,P6).:P1:,P2:,P3:,P4:,P5:,P6:,P7:,P8:().2?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " <reflections>\n",
      "- P4P3,P4\n",
      "- P4P3\n",
      "- P1,,\n",
      "- P1\n",
      "</reflections>\n",
      "\n",
      "{\"action\":\"WolfVote\",\"target\":\"P7\"}\n",
      "\n",
      ":P7,P4,P7,P3P4,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:54:21 AM \t\t===== DoAction NIGHT 2 P3 ======\n",
      "03/05/2024 02:54:21 AM \n",
      " [ROUND ACTION]={'time': 'NIGHT 2', 'player': 'P3', 'status': 1, 'role': '', 'character': '', 'response': ['{\"action\":\"WolfVote\",\"target\":\"P7\"}']}\n",
      "\n",
      "03/05/2024 02:54:21 AM \t\t===== DoMemory NIGHT 2 P6 ======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ,P5P4P3,P1P3P7P4,P6P7P3,P4P4P3,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:54:24 AM \t\t===== DoReflect NIGHT 2 P6 ======\n",
      "03/05/2024 02:54:24 AM \t\t===== DoAnswer NIGHT 2 P6 ======\n",
      "03/05/2024 02:54:24 AM \tQUESTION: NIGHT 2,P6(,:P3,P6).:P1:,P2:,P3:,P4:,P5:,P6:,P7:,P8:()...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\"action\":\"WolfVote\",\"target\":\"P7\"}\n",
      "\n",
      ":P7,,,P7,,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:54:28 AM \t\t===== DoAnswer NIGHT 2 P6 ======\n",
      "03/05/2024 02:54:28 AM \tQUESTION: NIGHT 2,P6(,:P3,P6).:P1:,P2:,P3:,P4:,P5:,P6:,P7:,P8:().2?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\"action\":\"WolfVote\",\"target\":\"P7\"}\n",
      "\n",
      ":P7,,,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:54:30 AM \t\t===== DoAction NIGHT 2 P6 ======\n",
      "03/05/2024 02:54:30 AM \n",
      " [ROUND ACTION]={'time': 'NIGHT 2', 'player': 'P6', 'status': 1, 'role': '', 'character': '', 'response': ['{\"action\":\"WolfVote\",\"target\":\"P7\"}']}\n",
      "\n",
      "03/05/2024 02:54:30 AM \t===== NIGHT 2 PostAction ======\n",
      "03/05/2024 02:54:30 AM \t [wolf_votes]: ['P7'], [player_vote_name]: Counter({'P7': 2})\n",
      "03/05/2024 02:54:30 AM \n",
      " [WOLF VOTE]={'time': 'NIGHT 2', 'player': 'P7', 'status': 0, 'role': '', 'character': '', 'response': 'P7NIGHT 2'}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1,P1P3,P3P6P5,P5P3P3P5,P4P5,P6P8,P1P3P6P4,P4P4P3\n",
      "\n",
      "2,P1P2P3P6P7,,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2024 02:54:36 AM !\n",
      "03/05/2024 02:54:36 AM .\n",
      "03/05/2024 02:54:36 AM ===== P1:,P2:,P3:,P4:,P5:,P6:,P7:,P8: EndGame =====\n",
      "03/05/2024 02:54:36 AM \t===== input_tokens: 3079652 output_tokens 6971 ======\n",
      "03/05/2024 02:54:36 AM \t===== elapsed_time: 216.95154476165771 ======\n"
     ]
    }
   ],
   "source": [
    "from utils.GamePlayer import GamePlayer\n",
    "from utils.GameMaster import GameMaster\n",
    "from utils.PeTemplates import *\n",
    "from utils import ParseJson, print_ww, Print, Info, Debug, Warn, Error\n",
    "\n",
    "llm = claude3_Sonnet\n",
    "GM = GameMaster(10, llm, False)\n",
    "GM.ResetGame()\n",
    "GM.RunGame()\n",
    "GM.EndGame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfcc21a-1ecf-4f3b-b73e-8d74baadb46e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
